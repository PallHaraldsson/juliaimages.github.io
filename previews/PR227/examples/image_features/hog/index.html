<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Object Detection using HOG · JuliaImages</title><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../democards/gridtheme.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img src="../../../assets/logo.png" alt="JuliaImages logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">JuliaImages</a></span></div><form class="docs-search" action="../../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><a class="tocitem" href="../../../install/">Getting started</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../../tutorials/quickstart/">Quickstart</a></li><li><a class="tocitem" href="../../../tutorials/arrays_colors/">Arrays, Numbers, and Colors</a></li><li><a class="tocitem" href="../../../tutorials/conversions_views/">Conversions vs. views</a></li><li><a class="tocitem" href="../../../tutorials/indexing/">Arrays: more advanced indexing</a></li></ul></li><li><span class="tocitem">Packages</span><ul><li><a class="tocitem" href="../../../pkgs/">Introduction</a></li><li><a class="tocitem" href="../../../pkgs/axes/">ImageAxes.jl</a></li><li><a class="tocitem" href="../../../pkgs/metadata/">ImageMetaData.jl</a></li><li><a class="tocitem" href="../../../pkgs/segmentation/">ImageSegmentation.jl</a></li><li><a class="tocitem" href="../../../pkgs/transformations/">ImageTransformations.jl</a></li><li><a class="tocitem" href="../../../pkgs/features/">ImageFeatures.jl</a></li></ul></li><li><a class="tocitem" href="../../">Demos</a></li><li><a class="tocitem" href="../../../function_reference/">References</a></li><li><a class="tocitem" href="../../../api_comparison/">Comparison with other image processing frameworks</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Object Detection using HOG</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Object Detection using HOG</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaImages/juliaimages.github.io/blob/source/docs/examples/image_features/hog.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Object-Detection-using-HOG"><a class="docs-heading-anchor" href="#Object-Detection-using-HOG">Object Detection using HOG</a><a id="Object-Detection-using-HOG-1"></a><a class="docs-heading-anchor-permalink" href="#Object-Detection-using-HOG" title="Permalink"></a></h1><p><a href="../hog.jl"><img src="https://img.shields.io/badge/download-julia-brightgreen.svg" alt="Source code"/></a> <img src="https://img.shields.io/badge/Author-Anchit%20Navelkar-blue" alt="Author"/> <img src="https://img.shields.io/badge/Author-Ashwani%20Rathee-blue" alt="Author"/> <img src="https://img.shields.io/date/1626048000" alt="Update time"/></p><p>In this tutorial, we will use Histogram of Oriented Gradient (HOG) feature descriptor based linear SVM to create a person detector. We will first create a person classifier and then use this classifier with a sliding window to identify and localize people in an image.</p><p>The key challenge in creating a classifier is that it needs to work with variations in illumination, pose and occlusions in the image. To achieve this, we will train the classifier on an intermediate representation of the image instead of the pixel-based representation. Our ideal representation (commonly called feature vector) captures information which is useful for classification but is invariant to small changes in illumination and occlusions. HOG descriptor is a gradient-based representation which is invariant to local geometric and photometric changes (i.e. shape and illumination changes) and so is a good choice for our problem. In fact HOG descriptors are widely used for object detection.</p><p>Download the script to get the training data <a href="https://drive.google.com/file/d/11G_9zh9N-0veQ2EL5WDGsnxRpihsqLX5/view?usp=sharing">here</a>. Download tutorial.zip, decompress it and run get<em>data.bash. (Change the variable `path</em>to<em>tutorial` in preprocess.jl and path to julia executable in get</em>data.bash). This script will download the required datasets. We will start by loading the data and computing HOG features of all the images.</p><pre><code class="language-julia hljs">using Images, ImageFeatures

path_to_tutorial = &quot;&quot;    # specify this path
pos_examples = &quot;$path_to_tutorial/tutorial/humans/&quot;
neg_examples = &quot;$path_to_tutorial/tutorial/not_humans/&quot;

n_pos = length(readdir(pos_examples))   # number of positive training examples
n_neg = length(readdir(neg_examples))   # number of negative training examples
n = n_pos + n_neg                       # number of training examples
data = Array{Float64}(undef, 3780, n)   # Array to store HOG descriptor of each image. Each image in our training data has size 128x64 and so has a 3780 length
labels = Vector{Int}(undef, n)          # Vector to store label (1=human, 0=not human) of each image.

for (i, file) in enumerate([readdir(pos_examples); readdir(neg_examples)])
    filename = &quot;$(i &lt;= n_pos ? pos_examples : neg_examples )/$file&quot;
    img = load(filename)
    data[:, i] = create_descriptor(img, HOG())
    labels[i] = (i &lt;= n_pos ? 1 : 0)
end</code></pre><p>Basically we now have an encoded version of images in our training data. This encoding captures useful information but discards extraneous information (illumination changes, pose variations etc). We will train a linear SVM on this data.</p><pre><code class="language-julia hljs">using LIBSVM

#Split the dataset into train and test set. Train set = 2500 images, Test set = 294 images.
random_perm = randperm(n)
train_ind = random_perm[1:2500]
test_ind = random_perm[2501:end]

model = svmtrain(data[:, train_ind], labels[train_ind]);</code></pre><p>Now let&#39;s test this classifier on some images.</p><pre><code class="language-julia hljs">img = load(&quot;$pos_examples/per00003.ppm&quot;)
descriptor = Array{Float64}(3780, 1)
descriptor[:, 1] = create_descriptor(img, HOG())

predicted_label, _ = svmpredict(model, descriptor);
print(predicted_label)                          # 1=human, 0=not human

# Get test accuracy of our model
predicted_labels, decision_values = svmpredict(model, data[:, test_ind]);
@printf &quot;Accuracy: %.2f%%\n&quot; mean((predicted_labels .== labels[test_ind])) * 100 # test accuracy should be &gt; 98%</code></pre><p>Try testing our trained model on more images. You can see that it performs quite well. Image</p><table><tr><th style="text-align: center"><img src="../assets/human1.png" alt="Original"/></th><th style="text-align: center"><img src="../assets/human2.png" alt="Original"/></th></tr><tr><td style="text-align: center">predicted_label = 1</td><td style="text-align: center">predicted_label = 1</td></tr></table><table><tr><th style="text-align: center"><img src="../assets/human3.png" alt="Original"/></th><th style="text-align: center"><img src="../assets/not-human1.jpg" alt="Original"/></th></tr><tr><td style="text-align: center">predicted_label = 1</td><td style="text-align: center">predicted_label = 0</td></tr></table><p>Next we will use our trained classifier with a sliding window to localize persons in an image.</p><p><img src="../assets/humans.jpg" alt="Original"/></p><pre><code class="language-julia hljs">img = load(&quot;path_to_tutorial/tutorial/humans.jpg&quot;)
rows, cols = size(img)

scores = Array{Float64}(22, 45)
descriptor = Array{Float64}(3780, 1)

#Apply classifier using a sliding window approach and store classification score for not-human at every location in score array
for j = 32:10:cols-32
    for i = 64:10:rows-64
        box = img[i-63:i+64, j-31:j+32]
        descriptor[:, 1] = create_descriptor(box, HOG())
        predicted_label, s = svmpredict(model, descriptor)
        scores[Int((i - 64) / 10)+1, Int((j - 32) / 10)+1] = s[1]
    end
end</code></pre><p><img src="../assets/scores.png" alt/></p><p>You can see that classifier gave low score to not-human class (i.e. high score to human class) at positions corresponding to humans in the original image. Below we threshold the image and supress non-minimal values to get the human locations. We then plot the bounding boxes using <code>ImageDraw</code>.</p><pre><code class="language-julia hljs">using ImageDraw, ImageView

scores[scores.&gt;0] = 0
object_locations = findlocalminima(scores)

rectangles = [
    [
        ((i[2] - 1) * 10 + 1, (i[1] - 1) * 10 + 1),
        ((i[2] - 1) * 10 + 64, (i[1] - 1) * 10 + 1),
        ((i[2] - 1) * 10 + 64, (i[1] - 1) * 10 + 128),
        ((i[2] - 1) * 10 + 1, (i[1] - 1) * 10 + 128),
    ] for i in object_locations
];

for rec in rectangles
    draw!(img, Polygon(rec), RGB{N0f8}(0, 0, 1.0))
end
imshow(img)</code></pre><p><img src="../assets/boxes.jpg" alt/></p><p>In our example we were lucky that the persons in our image had roughly the same size (128x64) as examples in our train set. We will generally need to take bounding boxes across multiple scales (and multiple aspect ratios for some object classes).</p><hr/><p><em>This page was generated using <a href="https://github.com/johnnychen94/DemoCards.jl">DemoCards.jl</a> and <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.5 on <span class="colophon-date" title="Sunday 5 September 2021 09:49">Sunday 5 September 2021</span>. Using Julia version 1.6.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
